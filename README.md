# 📰 2024 인하 인공지능 챌린지 - 한국 경제 기사 QA 모델 개발


## 소개

2024 인하대학교 인공지능 챌린지에 참가하여 진행한 **한국 경제 기사 기반 질의응답 모델 개발 프로젝트**입니다.  
주어진 뉴스 기사와 질의에 대해 **정확한 응답을 생성하는 모델**을 구축하는 것이 목표였으며,  
**프롬프트 엔지니어링**, **RAG 기반 추론**, **SFT**, **QLoRA 경량화 학습** 등을 단계별로 실험하며  
성능 개선을 위한 전략을 다양하게 탐색했습니다.


## 🗂 프로젝트 개요

- **프로젝트명**: 2024 인하 인공지능 챌린지 - 한국 경제 기사 기반 QA 모델링  
- **진행 기간**: 2024.07.02 ~ 2024.08.14  
- **최종 성과**: **학부생 트랙 총 60팀 중 8위 ㅜ__ㅜㅜ**  

- **역할**:
  - 프롬프트 설계 및 전처리  
  - SFT 및 QLoRA 실험  
  - RAG 기반 추론 파이프라인 구성  
  - 실험 결과 정리 및 모델 제출


## 📚 문제 정의 및 데이터 구성

- 주어진 입력:  
  - `본문 (뉴스 기사)` + `질문`
- 목표 출력:  
  - `질문에 대한 정확한 응답 (자유 서술형)` 생성
- 데이터 구성:  
  - 학습용: 본문-질문-답변 삼쌍 데이터  
  - 테스트: 본문-질문 제공, 답변 생성을 통해 평가
- 평가 기준:  
  - **문장 유사도 기반이 아닌**, **정답 문자열 일치 여부 기준 평가**


## 🧠 접근 전략 및 실험 흐름

1. **RAG (Retrieval-Augmented Generation)** 기반 추론부터 실험  
   - 간단한 TF-IDF 기반 retriever를 구성하여 기사 내용을 기반으로 답변 생성  
   - baseline으로도 높은 정확도 확보 가능

2. **프롬프트 엔지니어링**  
   - 뉴스 본문 요약 방식, 질문 강조 방식, 예시 포함 여부 등 다양한 프롬프트 변형 실험  
   - 단순한 RAG보다 높은 성능 확보

3. **SFT (Supervised Fine-Tuning)**  
   - HuggingFace 기반 Gemma2 모델을 SFT 방식으로 학습  
   - 프롬프트 설계와 결합하여 실제 테스트셋 성능 향상

4. **QLoRA 실험**  
   - VRAM 40GB 환경에서 QLoRA 경량화 학습 실험 진행  
   - 자원 효율적이었지만, 성능은 기존 SFT 대비 특별히 뛰어나진 않음  
   - 최종 제출 모델은 **SFT + RAG + 프롬프트 조정 버전**


## 🛠 사용 기술 및 스택

- **모델**: Gemma2 (base), Llama2 
- **경량화**: QLoRA (4-bit quantization), LoRA Adapter  
- **프롬프트 엔지니어링**: system + user 구조 설계, context window 조정  
- **파이프라인**: RAG, Fast retrieval + generation
- **언어**: Python  
- **라이브러리**: HuggingFace, LlamaIndex, Scikit-learn


## 📝 아쉬운 점

- **시간 부족으로 전면적인 모델 탐색이 어려웠음**  
  - 대회 기간 중 연구실 발표 준비와 병행하느라 실험 여유 부족해서 슬펐음 

- **평가 방식의 한계**  
  - 답변 평가가 `정확 일치 기반`으로 진행되어,  
    `"약 60%"`와 `"60%"` 같이 사실상 동일한 답변도 오답으로 처리됨  
  - **자연어 기반 유사도 평가 방식이 적용되지 않아**, 언어모델의 표현 다양성을 살리기 어려웠음

- **QLoRA 성능의 한계**  
  - 이론적으로는 메모리 효율적이고 성능 유지가 가능하다고 알려졌지만,  
    실제 실험에서는 기존 SFT 모델과 유의미한 차이가 발생하지 않아  
    **경량화 실험의 실질적 이점은 제한적**이었음, 내가 똑바로 못 쓴 것일까 
